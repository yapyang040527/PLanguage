{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPvC4/XiRRC5uZ5Hrs2I8oF",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/yapyang040527/PLanguage/blob/main/HW6_AI%E5%85%A8%E6%96%B9%E4%BD%8D%E5%AD%B8%E7%BF%92%E6%95%B8%E6%93%9A%E6%95%99%E7%B7%B4.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "ğŸš€ ã€AI å­¸ç¿’æ•¸æ“šæ•™ç·´ã€‘ï¼šæ‚¨çš„å€‹äººåŒ–å­¸ç¿’æ•¸æ“šä¸­æ¨ï¼\n",
        "å­å€¦äº†è¢«å‹•åœ°è¿½è¶•èª²è¡¨ï¼Ÿæˆ‘å€‘å°‡æ‚¨çš„å­¸ç¿’éç¨‹è½‰åŒ–ç‚ºä¸€å¥—æ•¸æ“šé©…å‹•çš„é«˜æ•ˆèƒ½å„€è¡¨æ¿ã€‚\n",
        "\n",
        "é€™å¥—ç³»çµ±çš„æ ¸å¿ƒæ˜¯æ™ºæ…§è¦åŠƒ (ğŸ§ )ï¼šå®ƒæœƒè®€å–æ‚¨çš„å®Œæ•´åŸå§‹èª²è¡¨ (ğŸ“…)ï¼Œæ ¹æ“šèª²ç¨‹é›£åº¦è‡ªå‹•è¨ˆç®—æœ€ä½³çš„é–“éš”è¤‡ç¿’æ’ç¨‹ (ğŸ“š)ï¼Œä¸¦å³æ™‚ç™¼å‡ºå­¸ç¿’éè¼‰è­¦å‘Š (âš ï¸)ï¼Œç¢ºä¿æ‚¨çš„æ™‚é–“åˆ†é…åœ¨æœ€ä½³ç‹€æ…‹ã€‚æ‰€æœ‰æ’ç¨‹èˆ‡åˆ†æçµæœéƒ½æœƒè‡ªå‹•åŒ¯å…¥æ‚¨çš„ Google Sheetï¼Œå¯¦ç¾å­¸ç¿’è¨˜éŒ„çš„å®Œå…¨è‡ªå‹•åŒ– (ğŸ“Š)ï¼\n",
        "\n",
        "ç•¶æ‚¨é‡åˆ°é›£é¡Œæ™‚ï¼Œæ‚¨çš„å°ˆå±¬ AI è¼”åŠ©éšŠä¼éš¨æ™‚å¾…å‘½ï¼š\n",
        "\n",
        "ğŸ’» ç¨‹å¼ç¢¼åŠ©æ‰‹ï¼šå¹«æ‚¨è§£é‡‹è¤‡é›œç¨‹å¼ç¢¼ã€æ‰¾ Bug (å°æ‡‰ç¨‹å¼èªè¨€/ä½œæ¥­ç³»çµ±)ã€‚\n",
        "\n",
        "ğŸ’° æ¡ˆä¾‹åˆ†æï¼šå”åŠ©æ‚¨è§£æ±ºæœƒè¨ˆå€Ÿè²¸æ³•å‰‡æˆ–çµ±è¨ˆæƒ…å¢ƒé¡Œã€‚\n",
        "\n",
        "ğŸ‡»ğŸ‡³ èªè¨€å­¸ç¿’åŠ©æ‰‹ï¼šæä¾›ç¿»è­¯ã€èªæ³•èˆ‡æƒ…å¢ƒåˆ†æï¼Œå¼·åŒ–æ‚¨çš„èªè¨€èƒ½åŠ›ã€‚\n",
        "\n",
        "â“ è¡“èªæŸ¥è©¢ & ğŸ“ å¯«ä½œå„ªåŒ–ï¼šå¿«é€ŸæŒæ¡æ ¸å¿ƒæ¦‚å¿µï¼Œä¸¦æå‡å­¸è¡“å¯«ä½œè³ªé‡ã€‚"
      ],
      "metadata": {
        "id": "EFjMaCFJWR7G"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# --- æ­¥é©Ÿ 1ï¼šé…ç½®åƒæ•¸èˆ‡èº«ä»½é©—è­‰ (å·²ä¿®æ­£èº«ä»½é©—è­‰éŒ¯èª¤) ---\n",
        "\n",
        "# ï¼ï¼é‡è¦ï¼šæ–°å¢äº† 'google.auth' çš„åŒ¯å…¥ï¼ï¼\n",
        "from google.colab import auth\n",
        "import gspread\n",
        "from google.auth import default as auth_default\n",
        "# -----------------------------------------------\n",
        "\n",
        "import os\n",
        "import pandas as pd\n",
        "from datetime import datetime, timedelta\n",
        "from google import genai\n",
        "import gradio as gr\n",
        "import re\n",
        "import requests\n",
        "import json\n",
        "\n",
        "# åˆå§‹åŒ–å…¨åŸŸè®Šæ•¸\n",
        "USE_GEMINI_API = False\n",
        "client = None\n",
        "MODEL = 'gemini-2.5-flash'\n",
        "day_mapping = {'MON': 0, 'TUE': 1, 'WED': 2, 'THU': 3, 'FRI': 4, 'SAT': 5, 'SUN': 6}\n",
        "\n",
        "# ğŸ¯ æ‚¨çš„ç¡¬ç·¨ç¢¼ API Key (ä¿æŒä¸è®Š)\n",
        "API_KEY_HARDCODE = 'AIzaSyDbzQMxubbjQ5Dr0mD57-kqVNjQ32Tpqog'\n",
        "\n",
        "# ğŸ¯ Google Sheet åƒæ•¸ (å·²ä¿®æ­£ç‚ºæ‚¨çš„ 'å·¥ä½œè¡¨1')\n",
        "SHEET_ID = '1pOXVGCarQ7JXjlIkkrS48EhNGKfNWTrwyLOuUcoBzjk'\n",
        "SHEET_NAME = 'å·¥ä½œè¡¨1'\n",
        "\n",
        "# å…¨åŸŸ Google Sheet å®¢æˆ¶ç«¯å’Œå·¥ä½œè¡¨å°è±¡\n",
        "gc = None\n",
        "worksheet = None\n",
        "\n",
        "def initialize_gemini():\n",
        "    \"\"\"åˆå§‹åŒ– Gemini Clientã€‚\"\"\"\n",
        "    global client, USE_GEMINI_API\n",
        "    try:\n",
        "        if not API_KEY_HARDCODE.startswith('AIzaSy'):\n",
        "             raise ValueError(\"API Key æ ¼å¼ä¸æ­£ç¢ºã€‚\")\n",
        "\n",
        "        client = genai.Client(api_key=API_KEY_HARDCODE)\n",
        "        USE_GEMINI_API = True\n",
        "        return \"âœ… Gemini Client æˆåŠŸåˆå§‹åŒ–ã€‚\"\n",
        "    except Exception as e:\n",
        "        USE_GEMINI_API = False\n",
        "        return f\"âŒ Gemini API åˆå§‹åŒ–å¤±æ•—ï¼š{e}ã€‚å°‡ä½¿ç”¨å‚™æ´æ¨¡æ“¬ã€‚\"\n",
        "\n",
        "def authenticate_google_sheet():\n",
        "    \"\"\"åŸ·è¡Œ Google Sheets API èº«ä»½é©—è­‰ã€‚ (ä¿®æ­£äº† 'auth.default' éŒ¯èª¤)\"\"\"\n",
        "    global gc, worksheet\n",
        "\n",
        "    print(\"\\n--- Google Sheets API èº«ä»½é©—è­‰å•Ÿå‹• (åªéœ€åŸ·è¡Œä¸€æ¬¡) ---\")\n",
        "    try:\n",
        "        # 1. é©—è­‰ Google å¸³æˆ¶ (é»æ“Šé€£çµä¸¦è²¼ä¸Šé©—è­‰ç¢¼)\n",
        "        auth.authenticate_user()\n",
        "\n",
        "        # 2. ç²å–ç”± Colab ç”¢ç”Ÿçš„ä½¿ç”¨è€…æ†‘è­‰ (ä½¿ç”¨ä¿®æ­£å¾Œçš„è·¯å¾‘)\n",
        "        credentials, _ = auth_default()\n",
        "\n",
        "        # 3. ä½¿ç”¨é€™äº›æ†‘è­‰æˆæ¬Š gspread\n",
        "        gc = gspread.authorize(credentials) # ä¿®æ­£æ­¤è™•\n",
        "\n",
        "    except Exception as e:\n",
        "        return f\"âŒ Google èº«ä»½é©—è­‰å¤±æ•—: {e}ã€‚ç„¡æ³•è‡ªå‹•å¯«å…¥ Sheetã€‚\"\n",
        "\n",
        "    # 4. é–‹å•ŸæŒ‡å®šè©¦ç®—è¡¨å’Œå·¥ä½œè¡¨\n",
        "    try:\n",
        "        spreadsheet = gc.open_by_key(SHEET_ID)\n",
        "        worksheet = spreadsheet.worksheet(SHEET_NAME)\n",
        "        return f\"âœ… Google Sheet é©—è­‰æˆåŠŸï¼Œç›®æ¨™å·¥ä½œè¡¨ï¼š'{SHEET_NAME}'ã€‚\"\n",
        "    except gspread.exceptions.WorksheetNotFound:\n",
        "        return f\"âŒ Google Sheet éŒ¯èª¤ï¼šæ‰¾ä¸åˆ°åç‚º '{SHEET_NAME}' çš„å·¥ä½œè¡¨ã€‚è«‹ç¢ºä¿å·¥ä½œè¡¨åç¨±æ­£ç¢ºã€‚\"\n",
        "    except Exception as e:\n",
        "        return f\"âŒ Google Sheet é€£æ¥å¤±æ•—: {e}ã€‚\"\n",
        "\n",
        "print(\"æ­¥é©Ÿä¸€ é…ç½®å®Œæˆï¼Œèº«ä»½é©—è­‰é‚è¼¯å·²æ›´æ–°ã€‚è«‹ç¹¼çºŒé‹è¡Œæ­¥é©ŸäºŒã€æ­¥é©Ÿä¸‰ã€æ­¥é©Ÿå››å’Œæ­¥é©Ÿäº”ã€‚\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PI2A-C__O1cx",
        "outputId": "59308e37-1b5a-49a0-c159-2ed08ff185c5"
      },
      "execution_count": 146,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "æ­¥é©Ÿä¸€ é…ç½®å®Œæˆï¼Œèº«ä»½é©—è­‰é‚è¼¯å·²æ›´æ–°ã€‚è«‹ç¹¼çºŒé‹è¡Œæ­¥é©ŸäºŒã€æ­¥é©Ÿä¸‰ã€æ­¥é©Ÿå››å’Œæ­¥é©Ÿäº”ã€‚\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# --- æ­¥é©Ÿ 2ï¼šæ ¸å¿ƒæ•¸æ“šèˆ‡è¨˜éŒ„å‡½æ•¸å®šç¾© (æ›´æ–°ï¼šæ–°å¢ç¨‹å¼ç¢¼åŠ©æ‰‹èˆ‡æ¡ˆä¾‹åˆ†æ) ---\n",
        "\n",
        "review_intervals = {1: 1, 2: 3, 3: 7} # è¤‡ç¿’é–“éš” (é€±)\n",
        "\n",
        "def create_mock_dataframe():\n",
        "    \"\"\"è¿”å›ç”¨æ–¼ã€è¤‡ç¿’æ’ç¨‹ã€çš„èª²ç¨‹æ•¸æ“š (æ’é™¤é«”è‚²èª²ï¼ŒåŒ…å«ä¸»é¡Œå’Œé›£åº¦)ã€‚\"\"\"\n",
        "    # é€™å¼µè¡¨ç”¨æ–¼ç”Ÿæˆè¤‡ç¿’æ’ç¨‹ (éœ€è¦ Topic, Keywords, Difficulty)\n",
        "    data = [\n",
        "        # èª²ç¨‹åç¨±, æ˜ŸæœŸ, ä¸Šèª²æ™‚é–“, ä¸Šèª²åœ°é», èª²ç¨‹ä¸»é¡Œ, é—œéµå­—, é›£åº¦\n",
        "        ['ç¶²éš›ç¶²è·¯æ¦‚è«–', 'TUE', '09:10-12:10', 'ç§‘æŠ€ç³»TB311æ•™å®¤', 'ç¶²è·¯å”è­°', 'TCP, IP, OSI Model, Routing', 3],\n",
        "        ['ç¨‹å¼èªè¨€', 'WED', '09:10-12:10', 'ç§‘æŠ€ç³»TB311æ•™å®¤', 'è¿´åœˆèˆ‡éè¿´', 'For-loop, Recursion, Stack, Data structure', 4],\n",
        "        ['è‹±æ–‡(ä¸‰):å­¸è¡“è‹±æ–‡å¯«ä½œèˆ‡å£èªè¡¨é”', 'THU', '13:20-15:10', 'ç¶œ210å±•è¦½å»³', 'Thesis Statement', 'Argumentation, Literature Review, Citation', 4],\n",
        "        ['çµ±è¨ˆå­¸', 'WED', '15:20-17:10', 'ç§‘æŠ€ç³»TB311æ•™å®¤', 'å‡è¨­æª¢å®š', 'P-value, Null Hypothesis, T-test, Regression', 5],\n",
        "        ['è¶Šå—èª(ä¸€)', 'WED', '17:20-18:10', 'ç§‘æŠ€ç³»TB311æ•™å®¤', 'åŸºç¤ç™¼éŸ³', 'Tones, Vowels, Diacritics, Conversation', 2],\n",
        "        ['æœƒè¨ˆå­¸', 'THU', '10:20-13:10', 'ç¶œ210å±•è¦½å»³', 'å€Ÿè²¸æ³•å‰‡', 'T-Account, Debit, Credit, Balance Sheet', 3],\n",
        "        ['ä½œæ¥­ç³»çµ±', 'FRI', '09:10-12:10', 'ç§‘æŠ€ç³»TB311æ•™å®¤', 'è¨˜æ†¶é«”ç®¡ç†', 'Paging, Virtual Memory, Process scheduling', 5],\n",
        "    ]\n",
        "    df = pd.DataFrame(data, columns=['Course', 'Day', 'Time', 'Location', 'Topic', 'Keywords', 'Difficulty'])\n",
        "    return df\n",
        "\n",
        "\n",
        "def get_full_class_schedule_data():\n",
        "    \"\"\"è¿”å›å®Œæ•´çš„èª²ç¨‹è¡¨æ•¸æ“šï¼ŒåŒ…å«é«”è‚²èª²ï¼Œç”¨æ–¼ Gradio é¡¯ç¤ºã€‚\"\"\"\n",
        "    full_data = [\n",
        "        # æ˜ŸæœŸ, èª²ç¨‹åç¨±, æ™‚é–“, åœ°é»\n",
        "        ['MON', 'é«”è‚²(å¤ªæ¥µæ‹³åˆç´š)', '10:20-12:10', 'æ­¦è¡“æˆ¿ä¸€'],\n",
        "        ['TUE', 'ç¶²éš›ç¶²è·¯æ¦‚è«–', '09:10-12:10', 'ç§‘æŠ€ç³»TB311æ•™å®¤'],\n",
        "        ['WED', 'ç¨‹å¼èªè¨€', '09:10-12:10', 'ç§‘æŠ€ç³»TB311æ•™å®¤'],\n",
        "        ['WED', 'çµ±è¨ˆå­¸', '15:20-17:10', 'ç§‘æŠ€ç³»TB311æ•™å®¤'],\n",
        "        ['WED', 'è¶Šå—èª(ä¸€)', '17:20-18:10', 'ç§‘æŠ€ç³»TB311æ•™å®¤'],\n",
        "        ['THU', 'æœƒè¨ˆå­¸', '10:20-13:10', 'ç¶œ210å±•è¦½å»³'],\n",
        "        ['THU', 'è‹±æ–‡(ä¸‰):å­¸è¡“è‹±æ–‡å¯«ä½œèˆ‡å£èªè¡¨é”', '13:20-15:10', 'ç¶œ210å±•è¦½å»³'],\n",
        "        ['FRI', 'ä½œæ¥­ç³»çµ±', '09:10-12:10', 'ç§‘æŠ€ç³»TB311æ•™å®¤'],\n",
        "    ]\n",
        "    df = pd.DataFrame(full_data, columns=['æ˜ŸæœŸ', 'èª²ç¨‹åç¨±', 'æ™‚é–“', 'åœ°é»'])\n",
        "    # æ’åºé‚è¼¯\n",
        "    day_order = {'MON': 1, 'TUE': 2, 'WED': 3, 'THU': 4, 'FRI': 5}\n",
        "    df['Day_Order'] = df['æ˜ŸæœŸ'].map(day_order)\n",
        "    df = df.sort_values(by=['Day_Order', 'æ™‚é–“']).drop(columns=['Day_Order']).reset_index(drop=True)\n",
        "    return df\n",
        "\n",
        "# --- Google Sheet è‡ªå‹•å¯«å…¥å‡½æ•¸ (log_ai_usage, log_activity_note) ä¿æŒä¸è®Š ---\n",
        "def log_ai_usage(tool_name: str, user_query: str, ai_response_summary: str, status: str):\n",
        "    \"\"\"å°‡ AI å·¥å…·çš„ä½¿ç”¨è¨˜éŒ„è¿½åŠ åˆ° Google Sheet çš„ A100 å„²å­˜æ ¼ä¹‹å¾Œã€‚\"\"\"\n",
        "    global worksheet\n",
        "    if worksheet is None: return\n",
        "    try:\n",
        "        log_date = datetime.now().strftime('%Y-%m-%d %H:%M')\n",
        "        record = [log_date, tool_name, user_query, ai_response_summary, status]\n",
        "\n",
        "        start_row = 100\n",
        "        all_values = worksheet.get_all_values()\n",
        "        write_row = len(all_values) + 1 if len(all_values) >= start_row else start_row\n",
        "\n",
        "        if write_row == start_row:\n",
        "             header = ['è¨˜éŒ„æ—¥æœŸ (Log Date)', 'AI å·¥å…· (Tool)', 'ä½¿ç”¨è€…æŸ¥è©¢ (User Query)', 'AI å›è¦†æ‘˜è¦ (AI Response Summary)', 'æˆåŠŸç‹€æ…‹ (Status)']\n",
        "             worksheet.update(f'A{start_row}', [header])\n",
        "             write_row += 1\n",
        "\n",
        "        worksheet.insert_row(record, write_row, value_input_option='USER_ENTERED')\n",
        "    except Exception as e:\n",
        "        print(f\"è­¦å‘Šï¼šAI ä½¿ç”¨è¨˜éŒ„å¯«å…¥å¤±æ•—: {e}\")\n",
        "        pass\n",
        "\n",
        "def log_activity_note(activity_type: str, duration: int, mood_score: int, ai_count: int, note: str) -> str:\n",
        "    \"\"\"æ´»å‹•è¨˜éŒ„å‡½æ•¸ï¼šå°‡è¨˜éŒ„è‡ªå‹•è¿½åŠ åˆ° Google Sheet çš„ A50 å„²å­˜æ ¼ä¸‹æ–¹ã€‚\"\"\"\n",
        "    global worksheet\n",
        "    if worksheet is None:\n",
        "        return \"âŒ Google Sheet å°šæœªé©—è­‰æˆ–é€£ç·šå¤±æ•—ï¼Œç„¡æ³•è‡ªå‹•å¯«å…¥ã€‚è«‹å…ˆåŸ·è¡Œæ’ç¨‹åˆ†æä»¥é©—è­‰ã€‚\"\n",
        "\n",
        "    try:\n",
        "        log_date = datetime.now().strftime('%Y-%m-%d %H:%M')\n",
        "        record = [log_date, activity_type, duration, mood_score, ai_count, note]\n",
        "\n",
        "        start_row = 50\n",
        "        all_values = worksheet.get_all_values()\n",
        "        write_row = len(all_values) + 1 if len(all_values) >= start_row else start_row\n",
        "\n",
        "        if write_row == start_row:\n",
        "             header = ['è¨˜éŒ„æ—¥æœŸ (Log Date)', 'æ´»å‹•é¡å‹ (Activity Type)', 'ç¸½æ™‚é•· (Duration_min)', 'æƒ…ç·’/ç²¾åŠ›åˆ†æ•¸ (Mood_1_5)', 'AI æŸ¥è©¢æ¬¡æ•¸ (AI Query Count)', 'å‚™è¨» (Notes)']\n",
        "             worksheet.update(f'A{start_row}', [header])\n",
        "             write_row += 1\n",
        "\n",
        "        worksheet.insert_row(record, write_row, value_input_option='USER_ENTERED')\n",
        "\n",
        "        return f\"\"\"\n",
        "        âœ… **è¨˜éŒ„è‡ªå‹•å¯«å…¥æˆåŠŸï¼**\\n\n",
        "        æ•¸æ“šå·²è¿½åŠ åˆ° Google Sheet '{SHEET_NAME}' å·¥ä½œè¡¨çš„ **ç¬¬ {write_row} è¡Œ (æ´»å‹•è¨˜éŒ„å€)**ã€‚\\n\n",
        "        å…§å®¹ï¼š{activity_type}, {duration}min, æƒ…ç·’{mood_score}/5\n",
        "        \"\"\"\n",
        "    except Exception as e:\n",
        "        return f\"âŒ è‡ªå‹•å¯«å…¥æ´»å‹•è¨˜éŒ„å¤±æ•—ï¼š{e}ã€‚è«‹æª¢æŸ¥ Google Sheet æ¬Šé™æˆ–é€£ç·šã€‚\"\n",
        "\n",
        "def explain_term_with_gemini(term):\n",
        "    \"\"\"åŠŸèƒ½ 5ï¼šè¡“èªè§£é‡‹å™¨ - è‡ªå‹•è¨˜éŒ„\"\"\"\n",
        "    tool_name = \"è¡“èªè§£é‡‹å™¨\"\n",
        "    if not USE_GEMINI_API: return \"âŒ Gemini API æœªå•Ÿç”¨ï¼Œç„¡æ³•æä¾›è¡“èªè§£é‡‹ã€‚\"\n",
        "    if not term: return \"è«‹è¼¸å…¥ä¸€å€‹è¡“èªã€‚\"\n",
        "\n",
        "    prompt = f\"è«‹ç”¨ä¸­æ–‡ç‚ºæˆ‘æ­£åœ¨å­¸ç¿’çš„ç§‘ç›® (ç§‘æŠ€/å·¥ç¨‹é¡) ç°¡æ½”åœ°è§£é‡‹ã€Œ{term}ã€é€™å€‹å°ˆæ¥­è¡“èªã€‚è«‹ä½¿ç”¨ Markdown æ ¼å¼ï¼Œä¸¦ç”¨ä¸€å€‹æ¯”å–»ä¾†å¹«åŠ©ç†è§£ã€‚\"\n",
        "    try:\n",
        "        response = client.models.generate_content(model=MODEL, contents=prompt)\n",
        "        summary = response.text.strip().replace('\\n', ' ')[:50] + \"...\"\n",
        "        log_ai_usage(tool_name, term, summary, \"æˆåŠŸ\")\n",
        "        return response.text.strip()\n",
        "    except Exception as e:\n",
        "        log_ai_usage(tool_name, term, str(e), \"å¤±æ•—\")\n",
        "        return f\"âš ï¸ è¡“èªæŸ¥è©¢æœå‹™è«‹æ±‚å¤±æ•—: {e}\"\n",
        "\n",
        "def translate_and_contextualize(phrase, target_language):\n",
        "    \"\"\"åŠŸèƒ½ 6ï¼šèªè¨€å­¸ç¿’åŠ©æ‰‹ - è‡ªå‹•è¨˜éŒ„ (ä¿ç•™)\"\"\"\n",
        "    tool_name = f\"èªè¨€åŠ©æ‰‹ ({target_language})\"\n",
        "    if not USE_GEMINI_API: return \"âŒ Gemini API æœªå•Ÿç”¨ã€‚è«‹ç¢ºèªç‹€æ…‹è¨Šæ¯ï¼Œæˆ–é‡æ–°é‹è¡Œç¨‹å¼ç¢¼ã€‚\"\n",
        "    if not phrase: return \"è«‹è¼¸å…¥ä¸€å€‹è¦ç¿»è­¯å’Œåˆ†æçš„ä¸­æ–‡æˆ–è‹±æ–‡ç‰‡èªã€‚\"\n",
        "\n",
        "    prompt = f\"\"\"è«‹æ“”ä»»å°ˆæ¥­çš„èªè¨€å°å¸«ï¼Œé‡å°é€™å€‹ä¸­æ–‡/è‹±æ–‡ç‰‡èªï¼šã€Œ{phrase}ã€ï¼š1. å°‡å…¶ç¿»è­¯æˆ {target_language}ã€‚2. èªªæ˜é€™å€‹è©å½™æˆ–ç‰‡èªåœ¨ {target_language} ä¸­çš„**èªæ³•çµæ§‹**æˆ–**å¸¸ç”¨æƒ…å¢ƒ**ã€‚3. å¦‚æœæ˜¯è¶Šå—èªï¼Œè«‹ç‰¹åˆ¥æä¾›å…¶**è²èª¿æ¨™è¨˜**ã€‚è«‹ä½¿ç”¨ Markdown æ ¼å¼è¼¸å‡ºï¼Œé‡é»åœ¨æ–¼æ•™å­¸ã€‚\"\"\"\n",
        "    try:\n",
        "        response = client.models.generate_content(model=MODEL, contents=prompt)\n",
        "        summary = response.text.strip().replace('\\n', ' ')[:50] + \"...\"\n",
        "        log_ai_usage(tool_name, phrase, summary, \"æˆåŠŸ\")\n",
        "        return response.text.strip()\n",
        "    except Exception as e:\n",
        "        log_ai_usage(tool_name, phrase, str(e), \"å¤±æ•—\")\n",
        "        return f\"âš ï¸ èªè¨€è¼”åŠ©æœå‹™è«‹æ±‚å¤±æ•— (Gemini API éŒ¯èª¤)ï¼š{e}ã€‚è«‹æª¢æŸ¥æ‚¨çš„ç¶²è·¯é€£ç·šæˆ– API Key ç‹€æ…‹ã€‚\"\n",
        "\n",
        "def academic_writing_assistant(user_draft):\n",
        "    \"\"\"åŠŸèƒ½ 8ï¼šå­¸è¡“å¯«ä½œåŠ©æ‰‹ - è‡ªå‹•è¨˜éŒ„\"\"\"\n",
        "    tool_name = \"å­¸è¡“å¯«ä½œåŠ©æ‰‹\"\n",
        "    if not USE_GEMINI_API: return \"âŒ Gemini API æœªå•Ÿç”¨ï¼Œç„¡æ³•æä¾›å­¸è¡“å¯«ä½œè¼”åŠ©ã€‚\"\n",
        "    if not user_draft: return \"è«‹è¼¸å…¥æ‚¨çš„è«–æ–‡æ‘˜è¦ã€å¼•è¨€æˆ– Thesis Statement é€²è¡Œåˆ†æã€‚\"\n",
        "\n",
        "    prompt = f\"\"\"æˆ‘æ­£åœ¨æ’°å¯«å­¸è¡“è«–æ–‡ï¼ˆå°æ‡‰èª²ç¨‹ï¼šè‹±æ–‡(ä¸‰):å­¸è¡“è‹±æ–‡å¯«ä½œèˆ‡å£èªè¡¨é”ï¼‰ï¼Œè«‹é‡å°ä»¥ä¸‹è‰ç¨¿é€²è¡Œåˆ†æèˆ‡æ”¹é€²ã€‚\n",
        "    1. æª¢æŸ¥å­¸è¡“èªæ°£å’Œæ­£å¼æ€§ã€‚\n",
        "    2. æå‡ºä¸€å€‹æ›´å¼·æœ‰åŠ›çš„ Thesis Statement ç¯„ä¾‹ã€‚\n",
        "    3. æ‰¾å‡ºæ½›åœ¨çš„èªæ³•æˆ–çµæ§‹éŒ¯èª¤ã€‚è«‹ä½¿ç”¨ Markdown æ ¼å¼è¼¸å‡ºã€‚\n",
        "\n",
        "    è‰ç¨¿ï¼š\n",
        "    {user_draft}\n",
        "    \"\"\"\n",
        "    try:\n",
        "        response = client.models.generate_content(model=MODEL, contents=prompt)\n",
        "        summary = response.text.strip().replace('\\n', ' ')[:50] + \"...\"\n",
        "        query_summary = user_draft[:20].replace('\\n', ' ') + \"...\"\n",
        "        log_ai_usage(tool_name, query_summary, summary, \"æˆåŠŸ\")\n",
        "        return response.text.strip()\n",
        "    except Exception as e:\n",
        "        query_summary = user_draft[:20].replace('\\n', ' ') + \"...\"\n",
        "        log_ai_usage(tool_name, query_summary, str(e), \"å¤±æ•—\")\n",
        "        return f\"âš ï¸ å¯«ä½œè¼”åŠ©æœå‹™è«‹æ±‚å¤±æ•—: {e}\"\n",
        "\n",
        "def code_explanation_assistant(code_snippet: str) -> str:\n",
        "    \"\"\"åŠŸèƒ½ 9ï¼šç¨‹å¼ç¢¼è§£é‡‹èˆ‡é™¤éŒ¯åŠ©æ‰‹ - è‡ªå‹•è¨˜éŒ„ (æ–°å¢)\"\"\"\n",
        "    tool_name = \"ç¨‹å¼ç¢¼åŠ©æ‰‹\"\n",
        "    if not USE_GEMINI_API: return \"âŒ Gemini API æœªå•Ÿç”¨ï¼Œç„¡æ³•æä¾›ç¨‹å¼ç¢¼è¼”åŠ©ã€‚\"\n",
        "    if not code_snippet: return \"è«‹è¼¸å…¥ä¸€æ®µ Python, C, æˆ– Java ç¨‹å¼ç¢¼ç‰‡æ®µã€‚\"\n",
        "\n",
        "    prompt = f\"\"\"è«‹æ“”ä»»è³‡æ·±ç¨‹å¼è¨­è¨ˆå°å¸«ï¼Œé‡å°ä»¥ä¸‹ç¨‹å¼ç¢¼ç‰‡æ®µï¼ˆå‡è¨­ç‚º Python/C/Java ä¹‹ä¸€ï¼‰ï¼š\n",
        "    1. èªªæ˜ç¨‹å¼ç¢¼çš„ç”¨é€”å’Œæ ¸å¿ƒé‚è¼¯ã€‚\n",
        "    2. æ‰¾å‡ºæ½›åœ¨çš„éŒ¯èª¤æˆ–æå‡ºå„ªåŒ–å»ºè­°ã€‚\n",
        "    3. å¦‚æœç¨‹å¼ç¢¼æœ‰éŒ¯ï¼Œè«‹æä¾›ä¿®æ­£å¾Œçš„ç‰ˆæœ¬ï¼ˆä¸å¿…åŸ·è¡Œï¼‰ã€‚è«‹ä½¿ç”¨ Markdown æ ¼å¼è¼¸å‡ºã€‚\n",
        "\n",
        "    ç¨‹å¼ç¢¼ï¼š\n",
        "    {code_snippet}\n",
        "    \"\"\"\n",
        "    try:\n",
        "        response = client.models.generate_content(model=MODEL, contents=prompt)\n",
        "        summary = response.text.strip().replace('\\n', ' ')[:50] + \"...\"\n",
        "        query_summary = code_snippet[:20].replace('\\n', ' ') + \"...\"\n",
        "        log_ai_usage(tool_name, query_summary, summary, \"æˆåŠŸ\")\n",
        "        return response.text.strip()\n",
        "    except Exception as e:\n",
        "        query_summary = code_snippet[:20].replace('\\n', ' ') + \"...\"\n",
        "        log_ai_usage(tool_name, query_summary, str(e), \"å¤±æ•—\")\n",
        "        return f\"âš ï¸ ç¨‹å¼ç¢¼è¼”åŠ©æœå‹™è«‹æ±‚å¤±æ•—: {e}\"\n",
        "\n",
        "def scenario_analysis_solver(scenario: str) -> str:\n",
        "    \"\"\"åŠŸèƒ½ 10ï¼šæ¡ˆä¾‹åˆ†æèˆ‡è§£æ±ºæ–¹æ¡ˆåŠ©æ‰‹ - è‡ªå‹•è¨˜éŒ„ (æ–°å¢)\"\"\"\n",
        "    tool_name = \"æ¡ˆä¾‹åˆ†æåŠ©æ‰‹\"\n",
        "    if not USE_GEMINI_API: return \"âŒ Gemini API æœªå•Ÿç”¨ï¼Œç„¡æ³•æä¾›æ¡ˆä¾‹åˆ†æã€‚\"\n",
        "    if not scenario: return \"è«‹è¼¸å…¥ä¸€å€‹æœƒè¨ˆã€çµ±è¨ˆæˆ–å•†æ¥­æ¡ˆä¾‹æƒ…å¢ƒã€‚\"\n",
        "\n",
        "    prompt = f\"\"\"è«‹æ“”ä»»æœƒè¨ˆ/çµ±è¨ˆ/å•†æ¥­é¡§å•ï¼Œé‡å°ä»¥ä¸‹æ¡ˆä¾‹æƒ…å¢ƒï¼š\n",
        "    1. è¾¨è­˜æ¡ˆä¾‹çš„æ ¸å¿ƒå•é¡Œé»ï¼ˆå¦‚æœƒè¨ˆä¸­çš„å€Ÿè²¸é—œä¿‚ã€çµ±è¨ˆä¸­çš„å‡è¨­é¡å‹ï¼‰ã€‚\n",
        "    2. æä¾›è§£æ±ºå•é¡Œçš„æ­¥é©Ÿæˆ–å…¬å¼ï¼ˆå¦‚T-Accountçš„æ‡‰ç”¨ã€T-testçš„é¸æ“‡ï¼‰ã€‚\n",
        "    3. çµ¦å‡ºä¸€å€‹ç°¡æ½”çš„æœ€çµ‚åˆ†æçµè«–ã€‚è«‹ä½¿ç”¨ Markdown æ ¼å¼è¼¸å‡ºã€‚\n",
        "\n",
        "    æ¡ˆä¾‹æƒ…å¢ƒï¼š\n",
        "    {scenario}\n",
        "    \"\"\"\n",
        "    try:\n",
        "        response = client.models.generate_content(model=MODEL, contents=prompt)\n",
        "        summary = response.text.strip().replace('\\n', ' ')[:50] + \"...\"\n",
        "        query_summary = scenario[:20].replace('\\n', ' ') + \"...\"\n",
        "        log_ai_usage(tool_name, query_summary, summary, \"æˆåŠŸ\")\n",
        "        return response.text.strip()\n",
        "    except Exception as e:\n",
        "        query_summary = scenario[:20].replace('\\n', ' ') + \"...\"\n",
        "        log_ai_usage(tool_name, query_summary, str(e), \"å¤±æ•—\")\n",
        "        return f\"âš ï¸ æ¡ˆä¾‹åˆ†ææœå‹™è«‹æ±‚å¤±æ•—: {e}\"\n",
        "\n",
        "# --- å…¶ä»–è¼”åŠ©å‡½æ•¸ (get_ai_review_advice, get_knowledge_network_analysis) ä¿æŒä¸è®Š ---\n",
        "def get_ai_review_advice(keywords, topic, difficulty):\n",
        "    if not USE_GEMINI_API: return f\"ğŸ’¡ å»ºè­°è‡ªè¡Œæœå°‹: '{keywords.split(',')[0].strip()}'\"\n",
        "\n",
        "    if difficulty >= 4:\n",
        "        prompt = f\"\"\"ä¸»é¡Œï¼š{topic}ï¼Œé—œéµå­—ï¼š{keywords}ã€‚é€™æ˜¯ä¸€å€‹é›£åº¦ç‚º {difficulty}/5 çš„ä¸»é¡Œã€‚è«‹ç‚ºé€™å€‹é«˜é›£åº¦ä¸»é¡Œè¨­è¨ˆä¸€å€‹**çµæ§‹åŒ–çš„è¤‡ç¿’å¤§ç¶±**ã€‚è¼¸å‡ºæ ¼å¼ï¼šå…ˆçµ¦å‡ºä¸€å€‹æ ¸å¿ƒç¸½çµ (1å¥)ï¼Œç„¶å¾Œç”¨ Markdown åˆ—è¡¨åˆ—å‡º 3 å€‹æœ€å…·æŒ‘æˆ°æ€§çš„**å•ç­”æç¤º**ï¼Œå¹«åŠ©ä½¿ç”¨è€…é€²è¡Œä¸»å‹•å›æ†¶ã€‚\"\"\"\n",
        "        prompt_type = \"ğŸ¯ è¤‡ç¿’å¤§ç¶±\"\n",
        "    else:\n",
        "        prompt = f\"\"\"ä¸»é¡Œï¼š{topic}ï¼Œé—œéµå­—ï¼š{keywords}ã€‚è«‹æä¾›ä¸€å€‹ç°¡æ½”çš„å­¸ç¿’å»ºè­°ï¼š1. æ ¸å¿ƒæ¦‚å¿µã€‚2. è¡Œå‹•å»ºè­° (ä¾‹å¦‚ï¼šå»ºè­°æœå°‹ YouTube é—œéµå­—)ã€‚è¼¸å‡º 30 å­—å…§ã€‚\"\"\"\n",
        "        prompt_type = \"ğŸ¤– AI å»ºè­°\"\n",
        "    try:\n",
        "        response = client.models.generate_content(model=MODEL, contents=prompt)\n",
        "        return f\"**{prompt_type}**: {response.text.strip()}\"\n",
        "    except Exception as e: return f\"âš ï¸ Gemini æœå‹™è«‹æ±‚å¤±æ•—: {e}\"\n",
        "\n",
        "def get_knowledge_network_analysis(df_courses):\n",
        "    if not USE_GEMINI_API: return \"âŒ Gemini API æœªå•Ÿç”¨ï¼Œç„¡æ³•é€²è¡Œè·¨ä¸»é¡Œåˆ†æã€‚\"\n",
        "    topic_summary = \"\\n\".join([f\"- {row['Course']} ({row['Topic']}) - é›£åº¦: {row['Difficulty']}/5\" for _, row in df_courses.iterrows()])\n",
        "    prompt = f\"\"\"ä»¥ä¸‹æ˜¯æˆ‘çš„èª²ç¨‹ä¸»é¡Œæ¸…å–®... (çœç•¥é•·åº¦)\"\"\"\n",
        "    try:\n",
        "        response = client.models.generate_content(model=MODEL, contents=prompt)\n",
        "        return response.text.strip()\n",
        "    except Exception as e: return f\"âš ï¸ è·¨ä¸»é¡Œåˆ†ææœå‹™è«‹æ±‚å¤±æ•—: {e}\"\n",
        "\n",
        "print(\"æ­¥é©ŸäºŒ å‡½æ•¸å®šç¾©å®Œæˆï¼Œå·²æ–°å¢ç¨‹å¼ç¢¼åŠ©æ‰‹èˆ‡æ¡ˆä¾‹åˆ†æåŠŸèƒ½ã€‚\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "o_mFA7oQO3nQ",
        "outputId": "75f041a2-dba0-4a20-c56c-f4d99c815b80"
      },
      "execution_count": 147,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "æ­¥é©ŸäºŒ å‡½æ•¸å®šç¾©å®Œæˆï¼Œå·²æ–°å¢ç¨‹å¼ç¢¼åŠ©æ‰‹èˆ‡æ¡ˆä¾‹åˆ†æåŠŸèƒ½ã€‚\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# --- æ­¥é©Ÿ 3ï¼šä¸»åŸ·è¡Œé‚è¼¯èˆ‡æ’ç¨‹å¯«å…¥ (æ›´æ–°ï¼šç´å…¥æ™‚é–“èˆ‡åœ°é») ---\n",
        "\n",
        "def get_review_dates(row, start_date):\n",
        "    \"\"\"æ ¹æ“šèª²ç¨‹è³‡è¨Šå’Œé–“éš”ï¼Œç”Ÿæˆæœ¬å­¸æœŸçš„å¤šæ¬¡è¤‡ç¿’æ—¥æœŸ (èª¿ç”¨ AI å»ºè­°)\"\"\"\n",
        "    results = []\n",
        "    day_str = row['Day'].upper().strip()\n",
        "    if day_str not in day_mapping: return []\n",
        "\n",
        "    day_offset = day_mapping.get(day_str)\n",
        "    first_lesson_date = start_date + timedelta(days=day_offset)\n",
        "\n",
        "    for review_num, weeks_offset in review_intervals.items():\n",
        "        review_date = first_lesson_date + timedelta(weeks=weeks_offset)\n",
        "\n",
        "        resource_advice = get_ai_review_advice(\n",
        "            str(row['Keywords']),\n",
        "            str(row['Topic']),\n",
        "            int(row['Difficulty'])\n",
        "        )\n",
        "\n",
        "        results.append({\n",
        "            'Target_Date': review_date.strftime('%Y-%m-%d'),\n",
        "            'Day_of_Week': review_date.strftime('%a'),\n",
        "            'Course': row['Course'],\n",
        "            'Time': row['Time'], # <<< æ–°å¢æ¬„ä½\n",
        "            'Location': row['Location'], # <<< æ–°å¢æ¬„ä½\n",
        "            'Topic': row['Topic'],\n",
        "            'Review_Type': f'ç¬¬ {review_num} æ¬¡è¤‡ç¿’ ({weeks_offset} é€±å¾Œ)',\n",
        "            'Difficulty': row['Difficulty'],\n",
        "            'Priority_Score': row['Difficulty'] * (1 / weeks_offset),\n",
        "            'AI_Review_Advice': resource_advice\n",
        "        })\n",
        "    return results\n",
        "\n",
        "\n",
        "def run_analysis(start_date_str):\n",
        "    \"\"\"ä¸»åˆ†æå‡½æ•¸ï¼šåŸ·è¡Œ Google Sheet é©—è­‰ã€æ’ç¨‹è¨ˆç®—ã€é¢¨éšªè©•ä¼°èˆ‡æ•¸æ“šå¯«å…¥ A1 å€\"\"\"\n",
        "\n",
        "    # 0. åˆå§‹åŒ–å’Œé©—è­‰\n",
        "    init_status = initialize_gemini()\n",
        "    auth_status = authenticate_google_sheet()\n",
        "    network_analysis_report = \"\"\n",
        "    risk_assessment_report = \"\"\n",
        "\n",
        "    # 1. æª¢æŸ¥æ—¥æœŸ\n",
        "    try:\n",
        "        start_date = datetime.strptime(start_date_str, '%Y-%m-%d')\n",
        "    except ValueError:\n",
        "        return pd.DataFrame(), \"\", \"\", f\"âŒ éŒ¯èª¤ï¼šèµ·å§‹æ—¥æœŸæ ¼å¼éŒ¯èª¤ (æ‡‰ç‚º YYYY-MM-DD)ã€‚ {init_status}\\n{auth_status}\"\n",
        "\n",
        "    # 2. è®€å–èª²ç¨‹æ•¸æ“š\n",
        "    df_courses = create_mock_dataframe()\n",
        "    df_courses['Difficulty'] = pd.to_numeric(df_courses['Difficulty'], errors='coerce').fillna(1).astype(int)\n",
        "\n",
        "    # 3. åŸ·è¡Œæ’ç¨‹è¨ˆç®—\n",
        "    full_schedule_list = []\n",
        "    for _, row in df_courses.iterrows():\n",
        "        reviews = get_review_dates(row, start_date)\n",
        "        full_schedule_list.extend(reviews)\n",
        "\n",
        "    df_full_schedule = pd.DataFrame(full_schedule_list)\n",
        "    df_final_output = df_full_schedule.sort_values(\n",
        "        by=['Target_Date', 'Priority_Score'],\n",
        "        ascending=[True, False]\n",
        "    ).reset_index(drop=True)\n",
        "\n",
        "    # 4. åŸ·è¡Œ AI å…¨å±€åˆ†æ (åŠŸèƒ½ 2 & 4 å¼·åŒ–) - (ä¿®æ­£é¢¨éšªè©•ä¼°ä»¥åŒ¹é…æ–°æ™‚é–“)\n",
        "    if USE_GEMINI_API:\n",
        "        network_analysis_report = get_knowledge_network_analysis(df_courses)\n",
        "\n",
        "        # æ ¹æ“š PDF èª²è¡¨æ›´æ–°æ˜ŸæœŸä¸‰èª²ç¨‹æ™‚é–“å’Œé¢¨éšªé»\n",
        "        wed_courses = df_courses[df_courses['Day'].str.upper() == 'WED']['Course'].tolist()\n",
        "        daily_risk_report = \"\"\n",
        "        if len(wed_courses) >= 4:\n",
        "            wed_list = 'ã€'.join(wed_courses)\n",
        "            daily_risk_report = f\"ğŸš¨ **æ¯æ—¥é›†ä¸­è­¦å‘Š (æ˜ŸæœŸä¸‰)ï¼š**æ‚¨çš„æ˜ŸæœŸä¸‰èª²ç¨‹ï¼ˆ{wed_list}ï¼‰æ¥µç‚ºå¯†é›†ï¼ˆ09:10 AM è‡³ 18:10 PMï¼‰ã€‚**å»ºè­°ï¼š**ç‰¹åˆ¥ç•™æ„ä¸‹åˆçš„**çµ±è¨ˆå­¸**ï¼ˆé›£åº¦ 5/5ï¼‰ï¼Œå»ºè­°åœ¨ 12:10-15:20 ä¹‹é–“å®‰æ’çŸ­æš«ä¼‘æ¯æˆ–è¼•é‡åˆé¤ã€‚\"\n",
        "        else:\n",
        "            daily_risk_report = \"âœ… æ¯æ—¥èª²ç¨‹åˆ†ä½ˆæ­£å¸¸ï¼Œç„¡å–®æ—¥éè¼‰é¢¨éšªã€‚\"\n",
        "\n",
        "        df_final_output['Week_Num'] = df_final_output['Target_Date'].apply(\n",
        "            lambda x: (datetime.strptime(x, '%Y-%m-%d') - start_date).days // 7\n",
        "        )\n",
        "        weekly_load = df_final_output.groupby('Week_Num')['Difficulty'].sum().reset_index()\n",
        "        high_risk_weeks = weekly_load[weekly_load['Difficulty'] > 12]\n",
        "\n",
        "        if not high_risk_weeks.empty:\n",
        "            risky_weeks_info = \"\\n\".join([f\"- ç¬¬ {row['Week_Num']} é€± (é›£åº¦ç¸½åˆ†: {row['Difficulty']})\" for _, row in high_risk_weeks.iterrows()])\n",
        "            risk_assessment_report = f\"{daily_risk_report}\\n\\nâš ï¸ **å­¸ç¿’éè¼‰è­¦å‘Š (æ¯é€±)ï¼š**ä»¥ä¸‹é€±æ¬¡è¤‡ç¿’ä»»å‹™éæ–¼é›†ä¸­ä¸”é›£åº¦é«˜ï¼ˆç¸½åˆ†è¶…é 12ï¼‰ï¼š\\n{risky_weeks_info}\\nå»ºè­°æ‚¨å°‡é€™äº›é€±æ¬¡çš„ä½é›£åº¦ä»»å‹™æå‰æˆ–å»¶å¾Œã€‚\"\n",
        "        else:\n",
        "            risk_assessment_report = f\"{daily_risk_report}\\n\\nâœ… è¤‡ç¿’æ’ç¨‹å£“åŠ›åˆ†ä½ˆå‡å‹»ï¼Œä¿æŒç©©å®šï¼\"\n",
        "\n",
        "\n",
        "    # 5. è¼¸å‡ºæ•´ç† (é¡¯ç¤ºçµ¦ Gradio çœ‹)\n",
        "    # !!! é€™è£¡æ–°å¢ Time å’Œ Location æ¬„ä½ !!!\n",
        "    df_display = df_final_output[[\n",
        "        'Target_Date', 'Day_of_Week', 'Course',\n",
        "        'Time', 'Location', # <<< æ–°å¢æ¬„ä½\n",
        "        'Topic', 'Review_Type', 'Difficulty', 'AI_Review_Advice'\n",
        "    ]]\n",
        "    difficulty_status = f\"æ‚¨è¨­å®šçš„èª²ç¨‹é›£åº¦ (å¹³å‡ {df_courses['Difficulty'].mean():.1f}/5) å·²è¢«ç´å…¥æ’ç¨‹æ¬Šé‡è¨ˆç®—ã€‚\"\n",
        "    final_status = f\"âœ… æ’ç¨‹ç”Ÿæˆå®Œç•¢ï¼å…± {len(df_display)} ç­†è¤‡ç¿’è¨˜éŒ„ã€‚ {init_status}\\n\\n**[åŠŸèƒ½ 1 æ‘˜è¦]** {difficulty_status}\\n{auth_status}\"\n",
        "\n",
        "    # 6. ğŸ¯ å¯«å…¥ Google Sheet (è‡ªå‹•å°å…¥ A1)\n",
        "    global worksheet\n",
        "    if worksheet is not None:\n",
        "        try:\n",
        "            # æº–å‚™æ•¸æ“š (åŒ…å«æ¨™é¡Œå’Œå¾ŒçºŒè¿½è¹¤æ¬„ä½)\n",
        "            # !!! é€™è£¡æ–°å¢ Time å’Œ Location æ¬„ä½åˆ° Sheet Header !!!\n",
        "            output_header = [\n",
        "                'Target_Date', 'Day_of_Week', 'Course', 'Time', 'Location',\n",
        "                'Topic', 'Review_Type', 'Difficulty', 'AI_Review_Advice',\n",
        "                'æ˜¯å¦å®Œæˆ (Completed?)', 'å¯¦éš›å®Œæˆæ—¥ (Actual Date)', 'å¯¦éš›æ™‚é•· (Actual_min)', 'å‚™è¨» (Notes)'\n",
        "            ]\n",
        "\n",
        "            # å°‡ DataFrame æ•¸æ“šè½‰ç‚ºåˆ—è¡¨ï¼Œä¸¦ç”¨ç©ºå­—ç¬¦ä¸²æ“´å±•ï¼Œä»¥åŒ¹é…è¿½è¹¤æ¬„ä½ (å…± 4 å€‹é¡å¤–æ¬„ä½)\n",
        "            output_data = df_display.values.tolist()\n",
        "            extended_data = [row + [''] * 4 for row in output_data]\n",
        "\n",
        "            # æ¸…ç†ä¸¦å¯«å…¥ A1 å€åŸŸ\n",
        "            worksheet.update('A1', [output_header] + extended_data, value_input_option='USER_ENTERED')\n",
        "            final_status += f\"\\n\\nğŸŸ¢ **æ’ç¨‹æ•¸æ“šå·²æˆåŠŸè‡ªå‹•å°å…¥åˆ° Google Sheet {SHEET_NAME} çš„ A1 å„²å­˜æ ¼ (æ’ç¨‹è¿½è¹¤å€)ã€‚**\"\n",
        "        except Exception as e:\n",
        "            final_status += f\"\\n\\nâŒ **æ’ç¨‹å¯«å…¥ Sheet å¤±æ•—ï¼** è«‹æª¢æŸ¥æ¬Šé™æˆ–ç¶²è·¯é€£ç·šã€‚éŒ¯èª¤: {e}\"\n",
        "\n",
        "    return df_display, final_status, network_analysis_report, risk_assessment_report\n",
        "\n",
        "print(\"æ­¥é©Ÿä¸‰ æ’ç¨‹åŸ·è¡Œé‚è¼¯å®Œæˆï¼Œå·²ç´å…¥æ™‚é–“èˆ‡åœ°é»ï¼Œä¸¦æ›´æ–°é¢¨éšªè©•ä¼°ã€‚\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "h-HJAYR3O7PU",
        "outputId": "65778f12-c0a1-4348-daac-7ca560c2b81c"
      },
      "execution_count": 148,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "æ­¥é©Ÿä¸‰ æ’ç¨‹åŸ·è¡Œé‚è¼¯å®Œæˆï¼Œå·²ç´å…¥æ™‚é–“èˆ‡åœ°é»ï¼Œä¸¦æ›´æ–°é¢¨éšªè©•ä¼°ã€‚\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# --- æ­¥é©Ÿ 4ï¼šæ§‹å»º Gradio ä»‹é¢ (æœ€çµ‚ç‰ˆæœ¬ï¼ŒåŒ…å«æ‰€æœ‰åŠŸèƒ½) ---\n",
        "\n",
        "EXAMPLE_START_DATE = '2025-11-24'\n",
        "\n",
        "with gr.Blocks(title=\"AI å…¨æ–¹ä½å­¸ç¿’æ•¸æ“šæ•™ç·´\") as demo:\n",
        "    gr.Markdown(\"# ğŸ§  AI å…¨æ–¹ä½å­¸ç¿’æ•¸æ“šæ•™ç·´ (Gemini-Powered Study Hub)\")\n",
        "\n",
        "    # --- åˆ†é ä¸€ï¼šæˆ‘çš„åŸå§‹èª²è¡¨ (æ‚¨çš„è¦æ±‚) ---\n",
        "    with gr.Tab(\"ğŸ“… æˆ‘çš„åŸå§‹èª²è¡¨\"):\n",
        "        gr.Markdown(\"## æœ¬å­¸æœŸå®Œæ•´èª²ç¨‹è¡¨ (å«æ™‚é–“èˆ‡åœ°é»)\")\n",
        "        gr.DataFrame(get_full_class_schedule_data(), label=\"æˆ‘çš„å®Œæ•´èª²è¡¨\")\n",
        "\n",
        "    # --- åˆ†é äºŒï¼šè¤‡ç¿’æ’ç¨‹èˆ‡å…¨å±€åˆ†æ (åŠŸèƒ½ 1, 2, 4) ---\n",
        "    with gr.Tab(\"ğŸ“š è¤‡ç¿’æ’ç¨‹èˆ‡å…¨å±€åˆ†æ\"):\n",
        "        gr.Markdown(\"## æ­¥é©Ÿä¸€ï¼šæ•¸æ“šåˆ†æèˆ‡è‡ªå‹•å¯«å…¥ Sheet å•Ÿå‹•\")\n",
        "        gr.Markdown(\"â„¹ï¸ **é‡è¦æç¤ºï¼š** é¦–æ¬¡åŸ·è¡Œæœƒè¦æ±‚æ‚¨é€²è¡Œ **Google èº«ä»½é©—è­‰**ã€‚æ’ç¨‹å°‡è‡ªå‹•å¯«å…¥ Sheet çš„ **A1 å„²å­˜æ ¼**ã€‚\")\n",
        "        with gr.Row():\n",
        "            start_date_input = gr.Textbox(label=\"å­¸æœŸèµ·å§‹åŸºæº–æ—¥ (YYYY-MM-DD)\", value=EXAMPLE_START_DATE, interactive=True)\n",
        "            btn_analyze = gr.Button(\"ğŸš€ åŸ·è¡Œå…¨å±€åˆ†æä¸¦ç”Ÿæˆæ’ç¨‹ (è‡ªå‹•å¯«å…¥ Sheet)\", variant=\"primary\")\n",
        "\n",
        "        output_final_status = gr.Textbox(label=\"ç‹€æ…‹èˆ‡åŸ·è¡Œçµæœ (è«‹ç•™æ„ Google èº«ä»½é©—è­‰æç¤º)\", lines=5)\n",
        "\n",
        "        gr.Markdown(\"---\")\n",
        "\n",
        "        with gr.Row():\n",
        "            with gr.Column(scale=2):\n",
        "                gr.Markdown(\"### ğŸ“ é–“éš”è¤‡ç¿’æ’ç¨‹è¡¨ (å·²è‡ªå‹•å¯«å…¥ Google Sheet A1)\")\n",
        "                output_df = gr.DataFrame(label=\"AI å­¸ç¿’æ’ç¨‹\", wrap=True)\n",
        "\n",
        "            with gr.Column(scale=1):\n",
        "                gr.Markdown(\"### ğŸ¤– å…¨å±€åˆ†æå ±å‘Š (åŠŸèƒ½ 2 & 4 å¼·åŒ–)\")\n",
        "                output_network = gr.Markdown(label=\"è·¨é ˜åŸŸçŸ¥è­˜é€£çµåˆ†æ\", visible=True)\n",
        "                output_risk = gr.Markdown(label=\"å­¸ç¿’é€²åº¦é¢¨éšªè©•ä¼°\")\n",
        "\n",
        "        btn_analyze.click(\n",
        "            fn=run_analysis,\n",
        "            inputs=[start_date_input],\n",
        "            outputs=[output_df, output_final_status, output_network, output_risk]\n",
        "        )\n",
        "\n",
        "    # --- åˆ†é ä¸‰ï¼šè¡“èªå³æ™‚æŸ¥è©¢ (åŠŸèƒ½ 5) ---\n",
        "    with gr.Tab(\"â“ è¡“èªå³æ™‚æŸ¥è©¢\"):\n",
        "        gr.Markdown(\"## å°ˆæ¥­è¡“èªè§£é‡‹ (ä½¿ç”¨è¨˜éŒ„æœƒè‡ªå‹•å¯«å…¥ Sheet **A100**)\")\n",
        "        term_input = gr.Textbox(label=\"è¼¸å…¥è¦æŸ¥è©¢çš„è¡“èª\", placeholder=\"ä¾‹å¦‚ï¼šTå‹å¸³ (T-Account)ã€ä½µè¡Œæ€§ (Concurrency)\")\n",
        "        btn_explain = gr.Button(\"ğŸ” æŸ¥è©¢è¡“èªè§£é‡‹\", variant=\"secondary\")\n",
        "        output_explanation = gr.Markdown(label=\"AI è¡“èªè§£é‡‹\")\n",
        "\n",
        "        btn_explain.click(\n",
        "            fn=explain_term_with_gemini,\n",
        "            inputs=[term_input],\n",
        "            outputs=[output_explanation]\n",
        "        )\n",
        "\n",
        "    # --- åˆ†é å››ï¼šèªè¨€å­¸ç¿’åŠ©æ‰‹ (åŠŸèƒ½ 6) ---\n",
        "    with gr.Tab(\"ğŸ‡»ğŸ‡³ èªè¨€å­¸ç¿’åŠ©æ‰‹ (è¶Šå—èª/è‹±æ–‡)\"): # ç¢ºä¿æ­¤åˆ†é å­˜åœ¨\n",
        "        gr.Markdown(\"## é‡å°èªè¨€èª²ç¨‹çš„å³æ™‚è¼”åŠ© (ä½¿ç”¨è¨˜éŒ„æœƒè‡ªå‹•å¯«å…¥ Sheet **A100**)\")\n",
        "\n",
        "        with gr.Row():\n",
        "            term_input_lang = gr.Textbox(label=\"è¼¸å…¥ä¸­æ–‡/è‹±æ–‡ç‰‡èª\", placeholder=\"ä¾‹å¦‚ï¼šå¾ˆé«˜èˆˆèªè­˜ä½ \")\n",
        "            lang_selector = gr.Radio([\"è¶Šå—èª\", \"è‹±æ–‡\"], label=\"ç›®æ¨™èªè¨€\", value=\"è¶Šå—èª\", info=\"é‡å°æ‚¨çš„è¶Šå—èª(ä¸€)å’Œè‹±æ–‡(ä¸‰)èª²ç¨‹è¨­è¨ˆ\")\n",
        "\n",
        "        btn_lang_explain = gr.Button(\"ğŸ” ç¿»è­¯èˆ‡æƒ…å¢ƒåˆ†æ\", variant=\"secondary\")\n",
        "        output_lang_explanation = gr.Markdown(label=\"AI èªè¨€å°å¸«åˆ†æ\")\n",
        "\n",
        "        btn_lang_explain.click(\n",
        "            fn=translate_and_contextualize,\n",
        "            inputs=[term_input_lang, lang_selector],\n",
        "            outputs=[output_lang_explanation]\n",
        "        )\n",
        "\n",
        "    # --- åˆ†é äº”ï¼šå­¸è¡“å¯«ä½œåŠ©æ‰‹ (åŠŸèƒ½ 8) ---\n",
        "    with gr.Tab(\"ğŸ“ å­¸è¡“å¯«ä½œåŠ©æ‰‹ (è‹±æ–‡ä¸‰)\"):\n",
        "        gr.Markdown(\"## é‡å°å­¸è¡“è‹±æ–‡å¯«ä½œèª²ç¨‹çš„è‰ç¨¿å„ªåŒ– (ä½¿ç”¨è¨˜éŒ„æœƒè‡ªå‹•å¯«å…¥ Sheet **A100**)\")\n",
        "        draft_input = gr.Textbox(\n",
        "            label=\"è¼¸å…¥æ‚¨çš„è«–æ–‡è‰ç¨¿ç‰‡æ®µ\",\n",
        "            placeholder=\"ä¾‹å¦‚ï¼šThe study examines the influence of network topology on data transmission efficiency using quantitative methods.\",\n",
        "            lines=5\n",
        "        )\n",
        "        btn_write_assist = gr.Button(\"âœï¸ åˆ†æèˆ‡å„ªåŒ–è‰ç¨¿\", variant=\"secondary\")\n",
        "        output_write_analysis = gr.Markdown(label=\"AI å¯«ä½œç·¨è¼¯åˆ†æ\")\n",
        "\n",
        "        btn_write_assist.click(\n",
        "            fn=academic_writing_assistant,\n",
        "            inputs=[draft_input],\n",
        "            outputs=[output_write_analysis]\n",
        "        )\n",
        "\n",
        "    # --- åˆ†é å…­ï¼šç¨‹å¼ç¢¼åŠ©æ‰‹ (åŠŸèƒ½ 9) ---\n",
        "    with gr.Tab(\"ğŸ’» ç¨‹å¼ç¢¼åŠ©æ‰‹\"):\n",
        "        gr.Markdown(\"## ç¨‹å¼ç¢¼è§£é‡‹èˆ‡é™¤éŒ¯ (å°æ‡‰ï¼šç¨‹å¼èªè¨€ã€ä½œæ¥­ç³»çµ±) (ä½¿ç”¨è¨˜éŒ„æœƒè‡ªå‹•å¯«å…¥ Sheet **A100**)\")\n",
        "        code_input = gr.Textbox(\n",
        "            label=\"è¼¸å…¥ç¨‹å¼ç¢¼ç‰‡æ®µ (Python/C/Java)\",\n",
        "            placeholder=\"ä¾‹å¦‚ï¼šdef fib(n): return fib(n-1) + fib(n-2)\",\n",
        "            lines=10\n",
        "        )\n",
        "        btn_code_assist = gr.Button(\"ğŸ’» åˆ†æèˆ‡é™¤éŒ¯\", variant=\"secondary\")\n",
        "        output_code_analysis = gr.Markdown(label=\"AI ç¨‹å¼ç¢¼åˆ†æ\")\n",
        "\n",
        "        btn_code_assist.click(\n",
        "            fn=code_explanation_assistant,\n",
        "            inputs=[code_input],\n",
        "            outputs=[output_code_analysis]\n",
        "        )\n",
        "\n",
        "    # --- åˆ†é ä¸ƒï¼šæ¡ˆä¾‹åˆ†æ (åŠŸèƒ½ 10) ---\n",
        "    with gr.Tab(\"ğŸ’° æ¡ˆä¾‹åˆ†æ (æœƒè¨ˆ/çµ±è¨ˆ)\"):\n",
        "        gr.Markdown(\"## æœƒè¨ˆå€Ÿè²¸æ³•å‰‡èˆ‡çµ±è¨ˆæƒ…å¢ƒæ±‚è§£ (å°æ‡‰ï¼šæœƒè¨ˆå­¸ã€çµ±è¨ˆå­¸) (ä½¿ç”¨è¨˜éŒ„æœƒè‡ªå‹•å¯«å…¥ Sheet **A100**)\")\n",
        "        scenario_input = gr.Textbox(\n",
        "            label=\"è¼¸å…¥æ¡ˆä¾‹æƒ…å¢ƒ\",\n",
        "            placeholder=\"ä¾‹å¦‚ï¼šå…¬å¸è³¼è²·äº†$1000çš„è¨­å‚™ï¼Œä¸¦ä»¥ç¾é‡‘æ”¯ä»˜ã€‚å¦‚ä½•è¨˜å¸³ï¼Ÿ\",\n",
        "            lines=5\n",
        "        )\n",
        "        btn_scenario_solve = gr.Button(\"ğŸ’° åˆ†ææ¡ˆä¾‹èˆ‡æä¾›è§£æ³•\", variant=\"secondary\")\n",
        "        output_scenario_solution = gr.Markdown(label=\"AI æ¡ˆä¾‹åˆ†æèˆ‡è§£æ³•\")\n",
        "\n",
        "        btn_scenario_solve.click(\n",
        "            fn=scenario_analysis_solver,\n",
        "            inputs=[scenario_input],\n",
        "            outputs=[output_scenario_solution]\n",
        "        )\n",
        "\n",
        "    # --- åˆ†é å…«ï¼šæ´»å‹•å¿«é€Ÿè¨˜éŒ„ (è‡ªå‹•è¿½åŠ åˆ° A50 ä¹‹å¾Œ) ---\n",
        "    with gr.Tab(\"ğŸ“ æ´»å‹•å¿«é€Ÿè¨˜éŒ„\"):\n",
        "        gr.Markdown(\"## å¿«é€Ÿè¨˜éŒ„ä»Šæ—¥å­¸ç¿’æ´»å‹• (è‡ªå‹•è¿½åŠ åˆ° Google Sheet **A50** å„²å­˜æ ¼ä¹‹å¾Œ)\")\n",
        "\n",
        "        with gr.Row():\n",
        "            activity_type_input = gr.Radio([\"å­¸ç¿’/èª²ç¨‹\", \"èªè¨€/æ–‡åŒ–\", \"é«”è‚²/å¥åº·\", \"å°ˆæ¡ˆ/å¯«ä½œ\"], label=\"æ´»å‹•é¡å‹\", value=\"å­¸ç¿’/èª²ç¨‹\")\n",
        "            duration_input = gr.Number(label=\"ç¸½æ™‚é•· (åˆ†é˜)\", minimum=1, value=60)\n",
        "            mood_input = gr.Slider(label=\"æƒ…ç·’/ç²¾åŠ›åˆ†æ•¸ (1=ä½, 5=é«˜)\", minimum=1, maximum=5, step=1, value=4)\n",
        "            ai_count_input = gr.Number(label=\"AI åŠ©æ‰‹ä½¿ç”¨æ¬¡æ•¸ (å¯é¸ï¼Œæ­¤è™•å¡«å¯«çš„æ¬¡æ•¸å°‡è¢«è¨˜éŒ„åˆ° A50 å€)\", minimum=0, value=0)\n",
        "\n",
        "        note_content_input = gr.Textbox(\n",
        "            label=\"å‚™è¨»\",\n",
        "            placeholder=\"ç°¡è¿°å…§å®¹ï¼Œä¾‹å¦‚ï¼šå®Œæˆè¿´åœˆä½œæ¥­ã€æ…¢è·‘ 30 åˆ†é˜\",\n",
        "            lines=2\n",
        "        )\n",
        "\n",
        "        btn_log_note = gr.Button(\"ğŸ’¾ å„²å­˜ä¸¦è‡ªå‹•å¯«å…¥ Google Sheet\", variant=\"primary\")\n",
        "        output_note_status = gr.Markdown(label=\"è¨˜éŒ„ç‹€æ…‹\")\n",
        "\n",
        "        btn_log_note.click(\n",
        "            fn=log_activity_note,\n",
        "            inputs=[activity_type_input, duration_input, mood_input, ai_count_input, note_content_input],\n",
        "            outputs=[output_note_status]\n",
        "        )\n",
        "\n",
        "print(\"æ­¥é©Ÿå›› Gradio ä»‹é¢æ§‹å»ºå®Œæˆï¼Œæ‰€æœ‰åŠŸèƒ½å‡å·²åŒ…å«ï¼Œè«‹é‹è¡Œæ­¥é©Ÿäº”ä»¥å•Ÿå‹•ã€‚\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Q99cujrnO8_k",
        "outputId": "194eceb9-d238-4cc3-d942-a8c088460ee6"
      },
      "execution_count": 149,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "æ­¥é©Ÿå›› Gradio ä»‹é¢æ§‹å»ºå®Œæˆï¼Œæ‰€æœ‰åŠŸèƒ½å‡å·²åŒ…å«ï¼Œè«‹é‹è¡Œæ­¥é©Ÿäº”ä»¥å•Ÿå‹•ã€‚\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# é‡æ–°åŸ·è¡Œ Gemini API åˆå§‹åŒ– (ç¢ºä¿åŠŸèƒ½æ­£å¸¸)\n",
        "print(initialize_gemini())\n",
        "\n",
        "# é‡æ–°åŸ·è¡Œ Google Sheet é©—è­‰èˆ‡é€£æ¥æ¸¬è©¦\n",
        "print(authenticate_google_sheet())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oGd1wq8_RJ1_",
        "outputId": "c25282af-88b5-4b07-f6af-a964d5e622cc"
      },
      "execution_count": 150,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "âœ… Gemini Client æˆåŠŸåˆå§‹åŒ–ã€‚\n",
            "\n",
            "--- Google Sheets API èº«ä»½é©—è­‰å•Ÿå‹• (åªéœ€åŸ·è¡Œä¸€æ¬¡) ---\n",
            "âœ… Google Sheet é©—è­‰æˆåŠŸï¼Œç›®æ¨™å·¥ä½œè¡¨ï¼š'å·¥ä½œè¡¨1'ã€‚\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# --- æ­¥é©Ÿ 5ï¼šé‹è¡Œæ‡‰ç”¨ç¨‹å¼ (å•Ÿå‹• Gradio) ---\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    print(\"æ­£åœ¨å•Ÿå‹• AI å…¨æ–¹ä½å­¸ç¿’æ•¸æ“šæ•™ç·´ï¼Œè«‹ç­‰å¾… Public URL...\")\n",
        "    demo.launch(share=True)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 632
        },
        "id": "_gHoT32TO-sT",
        "outputId": "30153cf8-df84-46a0-f107-0719d744a617"
      },
      "execution_count": 151,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "æ­£åœ¨å•Ÿå‹• AI å…¨æ–¹ä½å­¸ç¿’æ•¸æ“šæ•™ç·´ï¼Œè«‹ç­‰å¾… Public URL...\n",
            "Colab notebook detected. To show errors in colab notebook, set debug=True in launch()\n",
            "* Running on public URL: https://a524e23b909c899bc4.gradio.live\n",
            "\n",
            "This share link expires in 1 week. For free permanent hosting and GPU upgrades, run `gradio deploy` from the terminal in the working directory to deploy to Hugging Face Spaces (https://huggingface.co/spaces)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<div><iframe src=\"https://a524e23b909c899bc4.gradio.live\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
            ]
          },
          "metadata": {}
        }
      ]
    }
  ]
}